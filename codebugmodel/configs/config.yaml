num_workers: 16
batch_size: 512
epoch: 30
early_stop: 10

wandb_log: True
pre_embed: True

pre_train_structure:
  
  used: True
  exist: True
  ast_path: './model/model_2024-11-16_22-22-22/model_epoch_8_acc_0.7136752136752137_f1_0.30289017341040464_recall_0.29671574178935445_precision_0.30932703659976385.pth'
  cfg_path: './model/model_2024-11-16_22-15-37/model_epoch_7_acc_0.5695631528964862_f1_0.3918148272391815_recall_0.6613816534541337_precision_0.2783603431839847.pth'
  pdg_path: './model/model_2024-11-16_23-24-50/model_epoch_1_acc_0.6244064577397911_f1_0.3563873067534581_recall_0.4960362400906002_precision_0.2780952380952381.pth'

L1_alpha: 0
L2_alpha: 0

learning_rate:
  init: 1e-2
  step_size: 1
  gamma: 0.8

class_weight: [ 1.0, 1.0 ]

fine_tuning: False
best_model_file_path: './model/acc-f1-model-e13.pth'


data_set_name: "xxx"
sub_project: "xxx"
root_data_folder: "../joern/data/${data_set_name}/${sub_project}"


g_type: [ 'ast', 'cfg', 'pdg' ]
use_text: True


ast_train_data_path: "${root_data_folder}/ast_output_pickle_train"
ast_valid_data_path: "${root_data_folder}/ast_output_pickle_valid"
ast_test_data_path: "${root_data_folder}/ast_output_pickle_test"
cfg_train_data_path: "${root_data_folder}/cfg_output_pickle_train"
cfg_valid_data_path: "${root_data_folder}/cfg_output_pickle_valid"
cfg_test_data_path: "${root_data_folder}/cfg_output_pickle_test"
pdg_train_data_path: "${root_data_folder}/pdg_output_pickle_train"
pdg_valid_data_path: "${root_data_folder}/pdg_output_pickle_valid"
pdg_test_data_path: "${root_data_folder}/pdg_output_pickle_test"

codeBERT:
  output_size: 768
  model_path: "../codeBERT/code/saved_models/checkpoint-best-acc/model.bin"
  cache_dir: "../codeBERT/roberta_cache"
  pretrain_model_name_or_path: "microsoft/codebert-base"
  model_type: "roberta"


model:
  name: "Model"
  data_folder: "data"


  embedding:
    used: True
    name_novar: "codebert-base"
    name_usevar: "codet5-base"
    codebert-base:
      used: True
      model_type: "auto"
      fine_tuning: True
      cache_dir: "LanguageModel/pre-model/cache/codeBERT"
      path_dir: "LanguageModel/pre-model/codeBERT/microsoft-codebert-base"
      fine_tuning_path_novar: "LanguageModel/saved_models/Derived/codeBERT/microsoft-codebert-base/novar-3weight-lr1e-5"
      fine_tuning_path_usevar: "LanguageModel/saved_models/Derived/codeBERT/microsoft-codebert-base/usevar-3weight-lr1e-5"
      output_size: 768
      block_size: 512
      embed_size: ${model.embedding.codebert-base.output_size}
    codet5-base:
      used: True
      model_type: "t5"
      fine_tuning: True
      cache_dir: "LanguageModel/pre-model/cache/salesforce"
      path_dir: "LanguageModel/pre-model/salesforce/codet5-base"
      fine_tuning_path_novar: "LanguageModel/saved_models/Derived/salesforce/codet5-base/novar-3weight-lr1e-5"
      fine_tuning_path_usevar: "LanguageModel/saved_models/Derived/salesforce/codet5-base/usevar-3weight-lr1e-5"
      output_size: 768
      block_size: 512
      embed_size: ${model.embedding.codet5-base.output_size}

  w2v:
    used: True
    name: "myw2v_${model.w2v.project_name}_${model.w2v.sub_project}_${model.w2v.sg_name}.wv"
    w2v_path: "${model.data_folder}/word2vec/${model.w2v.name}"
    project_name: "xxx"
    sub_project: "xxx"
    source_data_dir_path_ast: "../joern/data/${model.w2v.project_name}/${model.w2v.sub_project}/ast_output_pickle_train"
    source_data_dir_path_cfg: "../joern/data/${model.w2v.project_name}/${model.w2v.sub_project}/cfg_output_pickle_train"
    source_data_dir_path_pdg: "../joern/data/${model.w2v.project_name}/${model.w2v.sub_project}/pdg_output_pickle_train"
    min_count: 1
    vector_size: 256
    max_vocab_size: 200000
    load_workers: 32
    workers: 32
    sg: 1
    sg_name: "Skip-gram"

  RNN:
    input_size: 256
    hidden_size: 256
    output_size: 256
    num_layers: 2
    drop_out: 0.5
    use_bi: true

  GCN:
    input_size: 256
    hidden_size: 512
    pooling_ratio: 0.8
    n_hidden_layers: 2
    drop_out: 0.3

  GGNN:
    input_size: 512
    output_size: 512
    hidden_output_size: 512
    pooling_ratio: 0.8
    num_layers: 3
    n_hidden_layers: 2
    drop_out: 0.3

  MLP:

    hidden_size: 1024
    n_hidden_layers: 2
    n_classes: 2
    drop_out: 0.1


joern:
  joern_path_root: "/opt/joern/joern-cli"
  joern_path_parse: "${joern.joern_path_root}/joern-parse"
  joern_path_export: "${joern.joern_path_root}/joern-export"

  data_folder: "data"


  export_format: [ 'ast', 'cfg', 'pdg' ]
  export_type: 'dot'

  generate_file_suffix: '.c'